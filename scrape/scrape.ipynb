{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape images\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "\n",
    "home = \"http://www.archiv.birdpictures.de/Kollektionen/pixtacy/index.php?_&-pg=105&-met=vtview&-prt=1\"\n",
    "\n",
    "result = requests.get(home)\n",
    "\n",
    "if result.status_code == 200:\n",
    "    soup = BeautifulSoup(result.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchors = 65, href anchors = 64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "all_a_tags = soup.findAll('a')\n",
    "all_a_tags_size = len(all_a_tags)\n",
    "\n",
    "\n",
    "all_a_tags_with_href = soup.findAll('a', attrs={'href': re.compile(\"^http://\")})\n",
    "all_a_tags_with_href_size = len(all_a_tags_with_href)\n",
    "\n",
    "\n",
    "print(f'anchors = {all_a_tags_size}, href anchors = {all_a_tags_with_href_size}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level links\n",
    "\n",
    "all_a_tags = soup.findAll('a', attrs={'href': re.compile(\"^http://\")})\n",
    "\n",
    "reg_exp = re.compile(r'index.php?_$amp;*')\n",
    "\n",
    "top_links = []\n",
    "for link in all_a_tags:\n",
    "    if (len(link.contents) == 3):\n",
    "        # print(type(link))\n",
    "        top_links.append(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloadable content\n",
    "\n",
    "downloadable = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.archiv.birdpictures.de/Kollektionen/pixtacy/images/lores/Abdimstorch/Abdimstorch_35A8864.jpg?\n",
      "http://www.archiv.birdpictures.de/Kollektionen/pixtacy/images/lores/Abdimstorch/Abdimstorch_35A8888.jpg?\n",
      "http://www.archiv.birdpictures.de/Kollektionen/pixtacy/images/lores/Abdimstorch/Abdimstorch_35A8910.jpg?\n",
      "http://www.archiv.birdpictures.de/Kollektionen/pixtacy/images/lores/Abdimstorch/Abdimstorch_35A8933.jpg?\n"
     ]
    }
   ],
   "source": [
    "result = requests.get(top_links[0])\n",
    "\n",
    "# print(top_links[0])\n",
    "\n",
    "soup = BeautifulSoup(result.content, \"html.parser\")\n",
    "\n",
    "images = soup.findAll('img', attrs={'data-preview': re.compile(\"^http://\")})\n",
    "\n",
    "for image in images:\n",
    "    print(image.get('data-preview'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n"
     ]
    }
   ],
   "source": [
    "for l in top_links:\n",
    "    result = requests.get(l)\n",
    "    if result.status_code == 200:\n",
    "        # Process images\n",
    "        soup = BeautifulSoup(result.content, \"html.parser\")\n",
    "        images = soup.findAll('img', attrs={'data-preview': re.compile(\"^http://\")})\n",
    "        for i in images:\n",
    "            downloadable.append(i)\n",
    "    else:\n",
    "        print(f'Failed to fetch results from link: {l}')\n",
    "        \n",
    "        \n",
    "print(len(downloadable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "\n",
    "s = set()\n",
    "for l in downloadable:\n",
    "    \n",
    "    # print(l.get('data-preview'))\n",
    "    s.add(l.get('data-pageid'))\n",
    "    \n",
    "    \n",
    "# The number of downloadable items should be the number of \"data-pageid\"\n",
    "# Each \"data-pageid\" is unique and can (therefore) be used as file name\n",
    "len(s) == len(downloadable)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998\n"
     ]
    }
   ],
   "source": [
    "## Save image files to disk\n",
    "\n",
    "import os\n",
    "import validators\n",
    "\n",
    "path = os.path.join('resources', 'images')\n",
    "\n",
    "reg_ex = re.compile(' ') \n",
    "\n",
    "for l in downloadable:\n",
    "    \n",
    "    url = l.get('data-preview')\n",
    "    \n",
    "    if validators.url(url):\n",
    "        file_name =  f\"{l.get('data-pageid')}.jpg\"\n",
    "        file_path = os.path.join(path, file_name)\n",
    "        urllib.request.urlretrieve(url, file_path)\n",
    "\n",
    "only_files = next(os.walk(path))[2]\n",
    "print(len(only_files))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
